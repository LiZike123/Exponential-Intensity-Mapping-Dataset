{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f545dd-87e1-4838-9936-c54cd9ed51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "FOLDER = #Folder with 30 images\n",
    "OUTDIR = os.path.join(FOLDER, \"\")\n",
    "\n",
    "K_FIXED = 0.00128633\n",
    "YB = 0.0\n",
    "YM = 245.0\n",
    "\n",
    "XB_Q = 90.0\n",
    "XM_Q = 70.0\n",
    "\n",
    "SAMPLE_N = 30\n",
    "RANDOM_SEED = 2026 \n",
    "\n",
    "SCALE = 0.25\n",
    "PROGRESS_STEP = 10\n",
    "\n",
    "MEDIAN_KSIZE = 5\n",
    "P_SEED = 97.0\n",
    "P_LOW = 60.0\n",
    "DILATE_PX = 15\n",
    "CLOSE_PX = 0\n",
    "\n",
    "def list_images_recursive(folder):\n",
    "    exts = (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.bmp\", \"*.tif\", \"*.tiff\")\n",
    "    files = []\n",
    "    for e in exts:\n",
    "        files.extend(glob.glob(os.path.join(folder, \"**\", e), recursive=True))\n",
    "    return sorted(files)\n",
    "\n",
    "def to_gray(img):\n",
    "    if img is None:\n",
    "        return None\n",
    "    if len(img.shape) == 2:\n",
    "        return img\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def ensure_u8(gray):\n",
    "    if gray is None:\n",
    "        return None\n",
    "    if gray.dtype == np.uint8:\n",
    "        return gray\n",
    "    if gray.dtype == np.uint16:\n",
    "        return (gray / 256).astype(np.uint8)\n",
    "    return cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "def maybe_resize(gray_u8, scale):\n",
    "    if scale is None or abs(scale - 1.0) < 1e-9:\n",
    "        return gray_u8\n",
    "    h, w = gray_u8.shape[:2]\n",
    "    new_w = max(1, int(w * scale))\n",
    "    new_h = max(1, int(h * scale))\n",
    "    return cv2.resize(gray_u8, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def largest_connected_component(binary_u8):\n",
    "    bin01 = (binary_u8 > 0).astype(np.uint8)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(bin01, connectivity=8)\n",
    "    if num_labels <= 1:\n",
    "        return np.zeros_like(binary_u8, dtype=np.uint8)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    max_idx = 1 + int(np.argmax(areas))\n",
    "    return (labels == max_idx).astype(np.uint8) * 255\n",
    "\n",
    "def build_masks_two_stage(I_u8, p_seed=97.0, p_low=60.0, dilate_px=15, close_px=0):\n",
    "    T_seed = np.percentile(I_u8, p_seed)\n",
    "    seed = (I_u8 >= T_seed).astype(np.uint8) * 255\n",
    "\n",
    "    if close_px and close_px > 0:\n",
    "        k = int(close_px)\n",
    "        if k % 2 == 0:\n",
    "            k += 1\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k, k))\n",
    "        seed = cv2.morphologyEx(seed, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    seed = largest_connected_component(seed)\n",
    "    seed01 = (seed > 0)\n",
    "\n",
    "    T_low = np.percentile(I_u8, p_low)\n",
    "    cand01 = (I_u8 >= T_low).astype(np.uint8)\n",
    "\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(cand01, connectivity=8)\n",
    "    if num_labels <= 1:\n",
    "        fg = seed.copy()\n",
    "    else:\n",
    "        best_label = 0\n",
    "        best_overlap = -1\n",
    "        for lab in range(1, num_labels):\n",
    "            comp = (labels == lab)\n",
    "            overlap = int(np.sum(comp & seed01))\n",
    "            if overlap > best_overlap:\n",
    "                best_overlap = overlap\n",
    "                best_label = lab\n",
    "        fg = (labels == best_label).astype(np.uint8) * 255 if best_label != 0 else seed.copy()\n",
    "\n",
    "    if dilate_px and dilate_px > 0:\n",
    "        k = int(dilate_px)\n",
    "        if k % 2 == 0:\n",
    "            k += 1\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k, k))\n",
    "        fg_d = cv2.dilate(fg, kernel, iterations=1)\n",
    "    else:\n",
    "        fg_d = fg.copy()\n",
    "\n",
    "    bg = (fg_d == 0).astype(np.uint8) * 255\n",
    "    return fg, bg\n",
    "\n",
    "\n",
    "def progress_report(i, n, t0, last_pct_reported):\n",
    "    pct = int((i + 1) * 100 / n)\n",
    "    if pct >= last_pct_reported + PROGRESS_STEP or pct == 100:\n",
    "        elapsed = time.time() - t0\n",
    "        rate = elapsed / max(1, i + 1)\n",
    "        eta = rate * (n - (i + 1))\n",
    "        print(f\"[PROGRESS] {pct}% ({i+1}/{n})  elapsed={elapsed:.1f}s  ETA≈{eta:.1f}s\")\n",
    "        return pct\n",
    "    return last_pct_reported\n",
    "\n",
    "\n",
    "def solve_m_c_fixed_k(xb, xm, yb, ym, k):\n",
    "    denom = np.exp(k * xm) - np.exp(k * xb)\n",
    "    if abs(denom) < 1e-12:\n",
    "        raise RuntimeError(\n",
    "            f\"Denominator too small: exp(k*xm)≈exp(k*xb). xb={xb:.3f}, xm={xm:.3f}.\"\n",
    "        )\n",
    "    m = (ym - yb) / denom\n",
    "    c = yb - m * np.exp(k * xb)\n",
    "    return float(m), float(c)\n",
    "\n",
    "def apply_transform(I_u8, m, k, c):\n",
    "    g = m * np.exp(k * I_u8.astype(np.float32)) + c\n",
    "    g = np.clip(g, 0, 255).astype(np.uint8)\n",
    "    return g\n",
    "\n",
    "def main():\n",
    "    all_files = list_images_recursive(FOLDER)\n",
    "    if len(all_files) == 0:\n",
    "        raise FileNotFoundError(f\"No images found in directory: {FOLDER}\")\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    if len(all_files) <= SAMPLE_N:\n",
    "        files = all_files\n",
    "    else:\n",
    "        files = random.sample(all_files, SAMPLE_N)\n",
    "        files = sorted(files)\n",
    "\n",
    "    n = len(files)\n",
    "\n",
    "    print(f\"[INFO] Total images found: {len(all_files)}\")\n",
    "    print(f\"[INFO] Random-sampled images used: {n} (SAMPLE_N={SAMPLE_N}, random seed={RANDOM_SEED})\")\n",
    "    print(f\"[INFO] Image scale factor: {SCALE}\")\n",
    "    print(f\"[INFO] Fixed k value={K_FIXED}, Target YB={YB}, Target YM={YM}\")\n",
    "    print(f\"[INFO] Anchor percentiles: xb=P{XB_Q}(BG), xm=P{XM_Q}(FG), cross-frame median will be calculated\")\n",
    "\n",
    "    ksize = MEDIAN_KSIZE if MEDIAN_KSIZE % 2 == 1 else MEDIAN_KSIZE + 1\n",
    "\n",
    "    xb_i_list, xm_i_list = [], []\n",
    "    records = []\n",
    "    valid = 0\n",
    "\n",
    "    print(\"\\n[STAGE 1] Calculating per-frame xb_i/xm_i anchors ...\")\n",
    "    t0 = time.time()\n",
    "    last_pct = 0\n",
    "\n",
    "    for i, fp in enumerate(files):\n",
    "        img = cv2.imread(fp, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            last_pct = progress_report(i, n, t0, last_pct)\n",
    "            continue\n",
    "\n",
    "        gray = ensure_u8(to_gray(img))\n",
    "        gray = maybe_resize(gray, SCALE)\n",
    "        I = cv2.medianBlur(gray, ksize)\n",
    "\n",
    "        fg, bg = build_masks_two_stage(I, p_seed=P_SEED, p_low=P_LOW,\n",
    "                                       dilate_px=DILATE_PX, close_px=CLOSE_PX)\n",
    "\n",
    "        fg_pixels = I[fg > 0]\n",
    "        bg_pixels = I[bg > 0]\n",
    "        if fg_pixels.size < 200 or bg_pixels.size < 200:\n",
    "            last_pct = progress_report(i, n, t0, last_pct)\n",
    "            continue\n",
    "\n",
    "        xb_i = float(np.percentile(bg_pixels, XB_Q))\n",
    "        xm_i = float(np.percentile(fg_pixels, XM_Q))\n",
    "\n",
    "        xb_i_list.append(xb_i)\n",
    "        xm_i_list.append(xm_i)\n",
    "        valid += 1\n",
    "        records.append((os.path.basename(fp), xb_i, xm_i, float(np.mean(fg > 0))))\n",
    "\n",
    "        last_pct = progress_report(i, n, t0, last_pct)\n",
    "\n",
    "    if valid < max(10, int(0.6 * n)):\n",
    "        raise RuntimeError(f\"Insufficient valid frames for anchor statistics: valid={valid}/{n} (minimum required: {max(10, int(0.6 * n))}).\")\n",
    "\n",
    "    xb_bar = float(np.median(xb_i_list))\n",
    "    xm_bar = float(np.median(xm_i_list))\n",
    "\n",
    "    print(\"\\n[RESULT] Stable cross-frame anchor values (median):\")\n",
    "    print(f\"  x_b_bar = {xb_bar:.3f}\")\n",
    "    print(f\"  x_m_bar = {xm_bar:.3f}\")\n",
    "\n",
    "    m, c = solve_m_c_fixed_k(xb_bar, xm_bar, YB, YM, K_FIXED)\n",
    "    print(\"\\n[RESULT] Calculated mkc parameters (fixed k):\")\n",
    "    print(f\"  m = {m:.6f}\")\n",
    "    print(f\"  k = {K_FIXED:.8f}\")\n",
    "    print(f\"  c = {c:.6f}\")\n",
    "\n",
    "    # Validation check\n",
    "    print(\"\\n[STAGE 2] Performing validation checks (FG saturation & BG output statistics) ...\")\n",
    "    sat_list = []\n",
    "    bg_med_list = []\n",
    "    bg_p90_list = []\n",
    "    t1 = time.time()\n",
    "    last_pct = 0\n",
    "\n",
    "    for i, fp in enumerate(files):\n",
    "        img = cv2.imread(fp, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            last_pct = progress_report(i, n, t1, last_pct)\n",
    "            continue\n",
    "\n",
    "        gray = ensure_u8(to_gray(img))\n",
    "        gray = maybe_resize(gray, SCALE)\n",
    "        I = cv2.medianBlur(gray, ksize)\n",
    "\n",
    "        fg, bg = build_masks_two_stage(I, p_seed=P_SEED, p_low=P_LOW,\n",
    "                                       dilate_px=DILATE_PX, close_px=CLOSE_PX)\n",
    "        g = apply_transform(I, m, K_FIXED, c)\n",
    "\n",
    "        fg_pixels = g[fg > 0]\n",
    "        bg_pixels = g[bg > 0]\n",
    "        if fg_pixels.size < 200 or bg_pixels.size < 200:\n",
    "            last_pct = progress_report(i, n, t1, last_pct)\n",
    "            continue\n",
    "\n",
    "        sat_list.append(float(np.mean(fg_pixels >= 255)))\n",
    "        bg_med_list.append(float(np.median(bg_pixels)))\n",
    "        bg_p90_list.append(float(np.percentile(bg_pixels, 90)))\n",
    "\n",
    "        last_pct = progress_report(i, n, t1, last_pct)\n",
    "\n",
    "    if len(sat_list) > 0:\n",
    "        print(\"\\n[VALIDATION CHECK] FG saturation ratio: median=%.3f, p90=%.3f\" %\n",
    "              (float(np.median(sat_list)), float(np.percentile(sat_list, 90))))\n",
    "        print(\"[VALIDATION CHECK] BG output grayscale values: median=%.2f, p90=%.2f\" %\n",
    "              (float(np.median(bg_med_list)), float(np.percentile(bg_p90_list, 90))))\n",
    "\n",
    "    os.makedirs(OUTDIR, exist_ok=True)\n",
    "    txt_path = os.path.join(OUTDIR, \"mkc_fixedk_random30_result.txt\")\n",
    "    csv_path = os.path.join(OUTDIR, \"anchors_per_frame_random30.csv\")\n",
    "\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"SOURCE_FOLDER={FOLDER}\\n\")\n",
    "        f.write(f\"Total_images_found={len(all_files)}\\n\")\n",
    "        f.write(f\"Sampled_images={n}, valid_frames={valid}, random_seed={RANDOM_SEED}\\n\")\n",
    "        f.write(f\"IMAGE_SCALE={SCALE}\\n\")\n",
    "        f.write(f\"Fixed_k_value={K_FIXED}\\n\")\n",
    "        f.write(f\"Target_anchor_values: YB={YB}, YM={YM}\\n\")\n",
    "        f.write(f\"Anchor_percentiles: xb_i=P{XB_Q}(BG), xm_i=P{XM_Q}(FG)\\n\")\n",
    "        f.write(f\"Stable_cross_frame_anchors: xb_bar={xb_bar:.6f}, xm_bar={xm_bar:.6f}\\n\")\n",
    "        f.write(f\"Calculated_transform_parameters: m={m:.6f}, c={c:.6f}\\n\")\n",
    "        if len(sat_list) > 0:\n",
    "            f.write(f\"FG_saturation_ratio_median={float(np.median(sat_list)):.6f}, FG_saturation_ratio_p90={float(np.percentile(sat_list,90)):.6f}\\n\")\n",
    "            f.write(f\"BG_output_gray_median={float(np.median(bg_med_list)):.6f}, BG_output_gray_p90={float(np.percentile(bg_p90_list,90)):.6f}\\n\")\n",
    "\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"filename,xb_i_p90_bg,xm_i_p70_fg,fg_area_ratio\\n\")\n",
    "        for name, xb_i, xm_i, fg_ratio in records:\n",
    "            f.write(f\"{name},{xb_i:.6f},{xm_i:.6f},{fg_ratio:.6f}\\n\")\n",
    "\n",
    "    print(f\"\\n[COMPLETED] Results summary saved to: {txt_path}\")\n",
    "    print(f\"[COMPLETED] Per-frame anchor values saved to: {csv_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
