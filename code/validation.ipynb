{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b7bd1-4eb2-4315-9100-c1e0ca2d4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import base64\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "LABEL_DIR =  #Label File\n",
    "IMG_DIR   =       #Validation folder\n",
    "LABEL_NAME = None \n",
    "\n",
    "OUT_CSV = os.path.join(LABEL_DIR, \"eval_final_perframe.csv\")\n",
    "OUT_TXT = os.path.join(LABEL_DIR, \"eval_final_summary.txt\")\n",
    "\n",
    "CANNY_LOW = 70\n",
    "CANNY_HIGH = 190\n",
    "BOUNDARY_TOL = 2 \n",
    "\n",
    "EVAL_BAND = 8\n",
    "\n",
    "BG_EXCLUDE_DILATE = 10\n",
    "\n",
    "MEDIAN_KSIZE = 3  \n",
    "M = 1326.395647  \n",
    "K = 0.00128633    \n",
    "C = -1368.862781  \n",
    "\n",
    "GROW_THRESH = 1 \n",
    "\n",
    "BOUNDARY_THICKNESS = 2\n",
    "\n",
    "PROGRESS_STEP = 10  \n",
    "\n",
    "def to_gray_u8(img):\n",
    "    if img is None:\n",
    "        return None\n",
    "    # If already grayscale\n",
    "    if len(img.shape) == 2:\n",
    "        g = img\n",
    "    else:\n",
    "        # Convert BGR to grayscale\n",
    "        g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Convert 16-bit to 8-bit if needed\n",
    "    if g.dtype == np.uint8:\n",
    "        return g\n",
    "    if g.dtype == np.uint16:\n",
    "        return (g / 256).astype(np.uint8)\n",
    "    \n",
    "    # Normalize to 0-255 if not 8-bit\n",
    "    return cv2.normalize(g, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "def load_img(jd, json_path):\n",
    "    img_data = jd.get(\"imageData\", None)\n",
    "    if img_data:\n",
    "        try:\n",
    "            data = base64.b64decode(img_data)\n",
    "            arr = np.frombuffer(data, dtype=np.uint8)\n",
    "            img = cv2.imdecode(arr, cv2.IMREAD_UNCHANGED)\n",
    "            if img is not None:\n",
    "                return img, None\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    imagePath = jd.get(\"imagePath\", \"\")\n",
    "    exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\")\n",
    "    candidates = []\n",
    "    \n",
    "    if imagePath:\n",
    "        candidates.append(os.path.basename(imagePath))\n",
    "    base = os.path.splitext(os.path.basename(json_path))[0]\n",
    "    candidates.append(base)\n",
    "\n",
    "    for c in candidates:\n",
    "        if c.lower().endswith(exts):\n",
    "            p = os.path.join(IMG_DIR, c)\n",
    "            if os.path.exists(p):\n",
    "                img = cv2.imread(p, cv2.IMREAD_UNCHANGED)\n",
    "                if img is not None:\n",
    "                    return img, p\n",
    "\n",
    "    for c in candidates:\n",
    "        b0 = os.path.splitext(c)[0]\n",
    "        for ext in exts:\n",
    "            p = os.path.join(IMG_DIR, b0 + ext)\n",
    "            if os.path.exists(p):\n",
    "                img = cv2.imread(p, cv2.IMREAD_UNCHANGED)\n",
    "                if img is not None:\n",
    "                    return img, p\n",
    "\n",
    "    for c in candidates:\n",
    "        b0 = os.path.splitext(c)[0]\n",
    "        hits = []\n",
    "        for ext in exts:\n",
    "            hits += glob.glob(os.path.join(IMG_DIR, b0 + \"*\" + ext))\n",
    "        if hits:\n",
    "            img = cv2.imread(hits[0], cv2.IMREAD_UNCHANGED)\n",
    "            if img is not None:\n",
    "                return img, hits[0]\n",
    "\n",
    "    return None, None\n",
    "\n",
    "def resolve_label_name(jd, preferred):\n",
    "    labels = []\n",
    "    for sh in jd.get(\"shapes\", []):\n",
    "        lab = sh.get(\"label\", None)\n",
    "        if lab is not None and lab.strip():\n",
    "            labels.append(lab.strip())\n",
    "    \n",
    "    uniq = sorted(set(labels))\n",
    "    if not uniq:\n",
    "        return None\n",
    "    \n",
    "    if preferred is None:\n",
    "        return uniq[0]\n",
    "    if preferred in uniq:\n",
    "        return preferred\n",
    "    return uniq[0]\n",
    "\n",
    "def ensure_closed(pts_xy):\n",
    "    if len(pts_xy) < 3:\n",
    "        return None\n",
    "    \n",
    "    p0 = pts_xy[0]\n",
    "    pL = pts_xy[-1]\n",
    "    if (abs(p0[0] - pL[0]) + abs(p0[1] - pL[1])) > 1e-6:\n",
    "        pts_xy = pts_xy + [p0]\n",
    "    return pts_xy\n",
    "\n",
    "def pts_to_int(pts_xy, h, w):\n",
    "    poly = np.array(pts_xy, dtype=np.float32)\n",
    "    poly = np.round(poly).astype(np.int32)\n",
    "    # Clip to image boundaries\n",
    "    poly[:, 0] = np.clip(poly[:, 0], 0, w - 1)\n",
    "    poly[:, 1] = np.clip(poly[:, 1], 0, h - 1)\n",
    "    return poly\n",
    "\n",
    "def mask_to_boundary(mask_u8):\n",
    "    ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    grad = cv2.morphologyEx(mask_u8, cv2.MORPH_GRADIENT, ker)\n",
    "    return (grad > 0).astype(np.uint8)\n",
    "\n",
    "def build_gt_mask_and_boundary(jd, label_name, h, w, thickness=2):\n",
    "    shapes = [sh for sh in jd.get(\"shapes\", []) if sh.get(\"label\") == label_name]\n",
    "    if not shapes:\n",
    "        return None, None\n",
    "\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    for sh in shapes:\n",
    "        st = sh.get(\"shape_type\", \"polygon\")\n",
    "        pts = sh.get(\"points\", [])\n",
    "        if len(pts) < 2:\n",
    "            continue\n",
    "        \n",
    "        pts_xy = [(float(p[0]), float(p[1])) for p in pts]\n",
    "\n",
    "        if st == \"rectangle\" and len(pts_xy) >= 2:\n",
    "            (x1,y1),(x2,y2) = pts_xy[0], pts_xy[1]\n",
    "            x1,x2 = min(x1,x2), max(x1,x2)\n",
    "            y1,y2 = min(y1,y2), max(y1,y2)\n",
    "            pts_xy = [(x1,y1),(x2,y1),(x2,y2),(x1,y2)]\n",
    "\n",
    "        if st in (\"polygon\", \"rectangle\") and len(pts_xy) >= 3:\n",
    "            pts_xy = ensure_closed(pts_xy)\n",
    "            if pts_xy is None:\n",
    "                continue\n",
    "            poly = pts_to_int(pts_xy, h, w)\n",
    "            cv2.fillPoly(mask, [poly], 255)\n",
    "\n",
    "    if int((mask > 0).sum()) > 0:\n",
    "        return mask, mask_to_boundary(mask)\n",
    "\n",
    "    bnd = np.zeros((h, w), dtype=np.uint8)\n",
    "    for sh in shapes:\n",
    "        pts = sh.get(\"points\", [])\n",
    "        if len(pts) < 2:\n",
    "            continue\n",
    "        \n",
    "        pts_xy = [(float(p[0]), float(p[1])) for p in pts]\n",
    "        if len(pts_xy) >= 3:\n",
    "            pts_xy = ensure_closed(pts_xy) or pts_xy\n",
    "        \n",
    "        poly = pts_to_int(pts_xy, h, w)\n",
    "        cv2.polylines(bnd, [poly], isClosed=False, color=255, thickness=thickness)\n",
    "\n",
    "    ff = bnd.copy()\n",
    "    seed = (0, 0)  # Seed point for flood fill\n",
    "    mask_ff = np.zeros((h + 2, w + 2), np.uint8)\n",
    "    cv2.floodFill(ff, mask_ff, seedPoint=seed, newVal=128)\n",
    "\n",
    "    inside = (ff == 0)\n",
    "    obj = (inside | (ff == 255)).astype(np.uint8) * 255\n",
    "    \n",
    "    if int((obj > 0).sum()) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    return obj, (bnd > 0).astype(np.uint8)\n",
    "\n",
    "def preprocess_exp(gray_u8):\n",
    "    g = M * np.exp(K * gray_u8.astype(np.float32)) + C\n",
    "    return np.clip(g, 0, 255).astype(np.uint8)\n",
    "\n",
    "def canny_edges(gray_u8):\n",
    "    return cv2.Canny(gray_u8, CANNY_LOW, CANNY_HIGH)\n",
    "\n",
    "def floodfill_region(gray_u8, seed_xy, thr):\n",
    "    h, w = gray_u8.shape[:2]\n",
    "    mask = np.zeros((h + 2, w + 2), np.uint8)  # +2 for flood fill border\n",
    "    img_ff = gray_u8.copy()\n",
    "    \n",
    "    flags = 8 | cv2.FLOODFILL_FIXED_RANGE\n",
    "    cv2.FLOODFILL_FIXED_RANGE\n",
    "    cv2.floodFill(img_ff, mask, seedPoint=seed_xy, newVal=255,\n",
    "                  loDiff=int(thr), upDiff=int(thr), flags=flags)\n",
    "    \n",
    "    # Remove border and return binary mask\n",
    "    return (mask[1:-1, 1:-1] != 0)\n",
    "\n",
    "def pick_seed_from_gt(gray_u8, gt_mask_u8):\n",
    "    gt01 = (gt_mask_u8 > 0)\n",
    "    # Mask out non-GT regions\n",
    "    vals = gray_u8.copy()\n",
    "    vals[~gt01] = 0\n",
    "    # Find coordinates of maximum intensity\n",
    "    y, x = np.unravel_index(int(np.argmax(vals)), gray_u8.shape)\n",
    "    return (int(x), int(y))\n",
    "\n",
    "def coverage(seg_bool, gt_mask_u8):\n",
    "    gt = (gt_mask_u8 > 0)\n",
    "    denom = int(gt.sum())\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    inter = int((seg_bool & gt).sum())\n",
    "    return float(inter / denom)\n",
    "\n",
    "def bg_false_edge_density(edge_u8, gt_mask_u8, exclude_dilate=10):\n",
    "    gt = (gt_mask_u8 > 0).astype(np.uint8) * 255\n",
    "    k = int(exclude_dilate)\n",
    "    if k % 2 == 0:\n",
    "        k += 1  # Ensure odd kernel size\n",
    "    ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k, k))\n",
    "    gt_d = cv2.dilate(gt, ker, iterations=1)\n",
    "    \n",
    "    bg = (gt_d == 0)\n",
    "    denom = int(bg.sum())\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    e = (edge_u8 > 0)\n",
    "    return float((e & bg).sum() / denom)\n",
    "\n",
    "def disk_kernel(radius):\n",
    "    r = int(radius)\n",
    "    k = 2 * r + 1\n",
    "    return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k, k))\n",
    "\n",
    "def boundary_band_mask(gt_boundary01_u8, band=8):\n",
    "    gt_b = gt_boundary01_u8 * 255\n",
    "    ker = disk_kernel(band)\n",
    "    # Dilate boundary to create band\n",
    "    dilated = cv2.dilate(gt_b, ker, iterations=1)\n",
    "    return (dilated > 0).astype(np.uint8)\n",
    "\n",
    "def boundary_f1_dilate(pred_edge_u8, gt_boundary01_u8, tol=2, pred_mask01=None):\n",
    "    pred = (pred_edge_u8 > 0).astype(np.uint8)\n",
    "    gt_b = gt_boundary01_u8.astype(np.uint8)\n",
    "\n",
    "    if pred_mask01 is not None:\n",
    "        pred = pred & pred_mask01.astype(np.uint8)\n",
    "\n",
    "    n_pred = int(pred.sum())\n",
    "    n_gt = int(gt_b.sum())\n",
    "    \n",
    "    if n_pred == 0 or n_gt == 0:\n",
    "        return 0.0\n",
    "\n",
    "    ker = disk_kernel(tol)\n",
    "    gt_d = cv2.dilate(gt_b * 255, ker, iterations=1) > 0\n",
    "    pred_d = cv2.dilate(pred * 255, ker, iterations=1) > 0\n",
    "\n",
    "    # Calculate true positives\n",
    "    hit_pred = int((pred.astype(bool) & gt_d).sum())\n",
    "    hit_gt = int((gt_b.astype(bool) & pred_d).sum())\n",
    "\n",
    "    prec = hit_pred / n_pred if n_pred > 0 else 0.0\n",
    "    rec = hit_gt / n_gt if n_gt > 0 else 0.0\n",
    "\n",
    "    if (prec + rec) < 1e-12:\n",
    "        return 0.0\n",
    "    return 2 * prec * rec / (prec + rec)\n",
    "\n",
    "def med_p90(vals):\n",
    "    vals = np.asarray(vals, dtype=np.float64)\n",
    "    # Filter out non-finite values\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    if vals.size == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    return (float(np.median(vals)), float(np.percentile(vals, 90)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    json_files = sorted(glob.glob(os.path.join(LABEL_DIR, \"*.json\")))\n",
    "    n_total = len(json_files)\n",
    "\n",
    "    if n_total == 0:\n",
    "        raise FileNotFoundError(f\"No JSON files found in directory: {LABEL_DIR}\")\n",
    "\n",
    "    rows = []  \n",
    "    cov_b_list = []  \n",
    "    cov_p_list = []  \n",
    "    f1_band_b_list = []  \n",
    "    f1_band_p_list = []\n",
    "    f1_full_b_list = []  \n",
    "    f1_full_p_list = []  \n",
    "    bg_b_list = []  \n",
    "    bg_p_list = [] \n",
    "\n",
    "    t_start = time.time()\n",
    "    last_pct = -1\n",
    "\n",
    "    for idx, json_path in enumerate(json_files, start=1):\n",
    "        try:\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                jd = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Failed to load JSON: {json_path} - {str(e)}\")\n",
    "            continue\n",
    "\n",
    "        img, img_path = load_img(jd, json_path)\n",
    "        if img is None:\n",
    "            print(f\"[WARNING] Failed to load image for: {json_path}\")\n",
    "            continue\n",
    "\n",
    "        gray = to_gray_u8(img)\n",
    "        h, w = gray.shape[:2]\n",
    "\n",
    "        label_used = resolve_label_name(jd, LABEL_NAME)\n",
    "        if label_used is None:\n",
    "            print(f\"[WARNING] No valid labels found in: {json_path}\")\n",
    "            continue\n",
    "\n",
    "        gt_mask, gt_boundary = build_gt_mask_and_boundary(jd, label_used, h, w, BOUNDARY_THICKNESS)\n",
    "        if gt_mask is None or int((gt_mask > 0).sum()) == 0:\n",
    "            print(f\"[WARNING] Invalid GT mask for: {json_path}\")\n",
    "            continue\n",
    "\n",
    "        seed = pick_seed_from_gt(gray, gt_mask)\n",
    "        band_mask = boundary_band_mask(gt_boundary, EVAL_BAND)\n",
    "\n",
    "        edges_baseline = canny_edges(gray)\n",
    "        seg_baseline = floodfill_region(gray, seed, GROW_THRESH)\n",
    "        cov_baseline = coverage(seg_baseline, gt_mask)\n",
    "        bg_baseline = bg_false_edge_density(edges_baseline, gt_mask, BG_EXCLUDE_DILATE)\n",
    "        f1_full_baseline = boundary_f1_dilate(edges_baseline, gt_boundary, BOUNDARY_TOL, None)\n",
    "        f1_band_baseline = boundary_f1_dilate(edges_baseline, gt_boundary, BOUNDARY_TOL, band_mask)\n",
    "\n",
    "        median_img = cv2.medianBlur(gray, MEDIAN_KSIZE)\n",
    "        preprocessed_img = preprocess_exp(median_img)\n",
    "        edges_pre = canny_edges(preprocessed_img)\n",
    "        seg_pre = floodfill_region(preprocessed_img, seed, GROW_THRESH)\n",
    "        cov_pre = coverage(seg_pre, gt_mask)\n",
    "        bg_pre = bg_false_edge_density(edges_pre, gt_mask, BG_EXCLUDE_DILATE)\n",
    "        f1_full_pre = boundary_f1_dilate(edges_pre, gt_boundary, BOUNDARY_TOL, None)\n",
    "        f1_band_pre = boundary_f1_dilate(edges_pre, gt_boundary, BOUNDARY_TOL, band_mask)\n",
    "\n",
    "        img_filename = os.path.basename(img_path) if img_path else os.path.splitext(os.path.basename(json_path))[0]\n",
    "        rows.append([\n",
    "            img_filename,\n",
    "            label_used,\n",
    "            seed[0],\n",
    "            seed[1],\n",
    "            cov_baseline,\n",
    "            cov_pre,\n",
    "            f1_band_baseline,\n",
    "            f1_band_pre,\n",
    "            f1_full_baseline,\n",
    "            f1_full_pre,\n",
    "            bg_baseline,\n",
    "            bg_pre\n",
    "        ])\n",
    "\n",
    "        cov_b_list.append(cov_baseline)\n",
    "        cov_p_list.append(cov_pre)\n",
    "        f1_band_b_list.append(f1_band_baseline)\n",
    "        f1_band_p_list.append(f1_band_pre)\n",
    "        f1_full_b_list.append(f1_full_baseline)\n",
    "        f1_full_p_list.append(f1_full_pre)\n",
    "        bg_b_list.append(bg_baseline)\n",
    "        bg_p_list.append(bg_pre)\n",
    "\n",
    "        current_pct = int(idx * 100 / n_total)\n",
    "        if current_pct >= last_pct + PROGRESS_STEP or idx == n_total:\n",
    "            elapsed = time.time() - t_start\n",
    "            print(f\"[PROGRESS] {current_pct}% ({idx}/{n_total}) | Elapsed: {elapsed:.1f}s\")\n",
    "            last_pct = current_pct\n",
    "\n",
    "    try:\n",
    "        with open(OUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            # Write header\n",
    "            csv_writer.writerow([\n",
    "                \"image_filename\",\n",
    "                \"label_used\",\n",
    "                \"seed_x\",\n",
    "                \"seed_y\",\n",
    "                \"coverage_baseline\",\n",
    "                \"coverage_preprocessed\",\n",
    "                \"f1_band_baseline\",\n",
    "                \"f1_band_preprocessed\",\n",
    "                \"f1_full_baseline\",\n",
    "                \"f1_full_preprocessed\",\n",
    "                \"bg_false_edge_density_baseline\",\n",
    "                \"bg_false_edge_density_preprocessed\"\n",
    "            ])\n",
    "            csv_writer.writerows(rows)\n",
    "        print(f\"[SUCCESS] CSV file saved to: {OUT_CSV}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to save CSV file: {str(e)}\")\n",
    "\n",
    "    try:\n",
    "        with open(OUT_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "            # Write basic information\n",
    "            f.write(\"=== Evaluation Summary ===\\n\")\n",
    "            f.write(f\"Total JSON files: {n_total}\\n\")\n",
    "            f.write(f\"Successfully evaluated: {len(rows)}\\n\")\n",
    "            f.write(f\"Elapsed time: {time.time() - t_start:.1f} seconds\\n\\n\")\n",
    "            \n",
    "            # Write parameters\n",
    "            f.write(\"=== Algorithm Parameters ===\\n\")\n",
    "            f.write(f\"Canny edge detection: low={CANNY_LOW}, high={CANNY_HIGH}\\n\")\n",
    "            f.write(f\"Boundary tolerance: {BOUNDARY_TOL} pixels\\n\")\n",
    "            f.write(f\"Evaluation band width: {EVAL_BAND} pixels\\n\")\n",
    "            f.write(f\"Background exclude dilation: {BG_EXCLUDE_DILATE} pixels\\n\")\n",
    "            f.write(f\"Median filter kernel size: {MEDIAN_KSIZE}\\n\")\n",
    "            f.write(f\"MKC transformation: M={M}, K={K}, C={C}\\n\")\n",
    "            f.write(f\"Region growing threshold: {GROW_THRESH}\\n\")\n",
    "            f.write(f\"Boundary thickness for polyline: {BOUNDARY_THICKNESS}\\n\\n\")\n",
    "            \n",
    "            f.write(\"=== Metric Summary (Median / 90th Percentile) ===\\n\")\n",
    "            \n",
    "            f.write(\"\\n1. Region Growing Coverage (higher is better)\\n\")\n",
    "            f.write(f\"   Baseline: {med_p90(cov_b_list)}\\n\")\n",
    "            f.write(f\"   Preprocessed: {med_p90(cov_p_list)}\\n\")\n",
    "            \n",
    "            f.write(\"\\n2. Boundary F1 Score (Band Region, higher is better)\\n\")\n",
    "            f.write(f\"   Baseline: {med_p90(f1_band_b_list)}\\n\")\n",
    "            f.write(f\"   Preprocessed: {med_p90(f1_band_p_list)}\\n\")\n",
    "            \n",
    "            f.write(\"\\n3. Boundary F1 Score (Full Image, higher is better)\\n\")\n",
    "            f.write(f\"   Baseline: {med_p90(f1_full_b_list)}\\n\")\n",
    "            f.write(f\"   Preprocessed: {med_p90(f1_full_p_list)}\\n\")\n",
    "            \n",
    "            f.write(\"\\n4. Background False Edge Density (lower is better)\\n\")\n",
    "            f.write(f\"   Baseline: {med_p90(bg_b_list)}\\n\")\n",
    "            f.write(f\"   Preprocessed: {med_p90(bg_p_list)}\\n\")\n",
    "        \n",
    "        print(f\"[SUCCESS] Summary TXT file saved to: {OUT_TXT}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to save summary TXT file: {str(e)}\")\n",
    "\n",
    "    print(\"\\n[FINISHED] Evaluation completed successfully!\")\n",
    "    print(f\"- Processed {len(rows)} out of {n_total} files\")\n",
    "    print(f\"- CSV output: {OUT_CSV}\")\n",
    "    print(f\"- Summary output: {OUT_TXT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Evaluation failed: {str(e)}\")\n",
    "        exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
